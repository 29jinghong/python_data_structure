What I learned from the past assinments:
    spider.py:
        scans for world food facts get the links useing BeautifulSoup and put them inside a data table 
        since the links all have a "href" tag its really easy to find.

    scan.py:
        learned how to use the sql command to extract the url
        use the url to extract data
        learned how to use BeautifulSoup soup to extract serten data 
            like: energy, fat, carbohydrates, fiber, etc.
        I reviewed how to make a tuple of more than 2 elements.
        learned how to use a mutle elements tuple to store data throgh a loop.
        learned that i should take all data from the database and then do every caculation on my local and upload it at the same time to lower the fequency to request to the dat base.

    json.py:
        in this program i learned how to use sqlite command to combine two tables.
        use the combined table to get energy, fat, carbohydrates, fiber, etc.
        turn the data got into a java script json data.
        Incounterd many probles with the biggest one being having problems with the "?" data stored in the prevous data but soved it with a check function.
